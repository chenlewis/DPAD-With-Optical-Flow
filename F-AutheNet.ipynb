{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wyattchen/anaconda3/envs/wyatt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from torchvision.models import resnet50, densenet121, vit_b_16, ViT_B_16_Weights, swin_b, Swin_B_Weights\n",
    "import torch.nn as nn\n",
    "import torch as t\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "from torchvision.transformsansforms import transforms as T\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "from PIL import Image\n",
    "from torchnet import meter\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "import visdom\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Information Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DefaultConfig(object):\n",
    "    env = 'ResNet50-Flow-spatial'\n",
    "    vis_port = 8097\n",
    "    model = 'ResNet50'\n",
    "    train_flow_data = 'train_flow_SCVD.csv'\n",
    "    valid_flow_data = 'valid_flow_SCVD.csv'\n",
    "    test_flow_data = 'test_flow_SCVD.csv'\n",
    "    \n",
    "    train_spatial_data = 'train_spatial_SCVD.csv'\n",
    "    valid_spatial_data = 'valid_spatial_SCVD.csv'\n",
    "    test_spatial_data = 'test_spatial_SCVD.csv'\n",
    "\n",
    "    save_model = './checkpoint/'\n",
    "    load_model_path = save_model + 'xx.pth'\n",
    "    batch_size_0 = 128\n",
    "    batch_size_1 = 128\n",
    "    use_gpu = True\n",
    "    num_workers = 4\n",
    "    print_freq = 20\n",
    "    result_file = save_model + 'xx.csv'\n",
    "    max_epoch = 20\n",
    "    lr = 0.0001\n",
    "    lr_decay = 0.5\n",
    "    weight_decay = 1e-4\n",
    "    scheduler = None\n",
    "    device = t.device('cuda:2') if use_gpu else t.device('cpu')\n",
    "    loss_weight = t.Tensor([1, 1]).to(device)\n",
    "\n",
    "    def _parse(self, kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            if not hasattr(self, k):\n",
    "                warnings.warn(\"Warning: opt has not attribut %s\" % k)\n",
    "            setattr(self, k, v)\n",
    "\n",
    "        print('user config:')\n",
    "        for k, v in self.__class__.__dict__.items():\n",
    "            if not k.startswith('_'):\n",
    "                print(k, getattr(self, k))\n",
    "                \n",
    "opt = DefaultConfig()\n",
    "criterion = nn.CrossEntropyLoss(weight = opt.loss_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet50_Spatial(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50_Spatial, self).__init__()\n",
    "        self.model = resnet50(pretrained = True)\n",
    "        self.model.fc = nn.Sequential()\n",
    "        for params in self.parameters():\n",
    "            params.requires_grad = False\n",
    "        self.fc1 = nn.Linear(2048, 256)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        feature = self.fc1(x)\n",
    "        return feature\n",
    "    \n",
    "    def get_optimizer(self, lr, weight_decay):\n",
    "        \n",
    "        return Adam(self.parameters(), lr = lr, weight_decay = weight_decay)\n",
    "    \n",
    "class ResNet50_Flow(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50_Flow, self).__init__()\n",
    "        self.model = resnet50(pretrained = True)\n",
    "        self.model.fc = nn.Sequential()\n",
    "        for params in self.parameters():\n",
    "            params.requires_grad = False\n",
    "        self.fc1 = nn.Linear(2048, 256)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        feature = self.fc1(x)\n",
    "        return feature\n",
    "    \n",
    "    def get_optimizer(self, lr, weight_decay):\n",
    "        \n",
    "        return Adam(self.parameters(), lr = lr, weight_decay = weight_decay)\n",
    "                    \n",
    "class ResNet50_Flow_Spatial(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50_Flow_Spatial, self).__init__()\n",
    "        self.flow = ResNet50_Flow()\n",
    "        self.spatial = ResNet50_Spatial()\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 2)\n",
    "        self.fc4 = nn.Linear(256, 2)\n",
    "        self.fc5 = nn.Linear(256, 2)\n",
    "            \n",
    "    def forward(self, x, y):\n",
    "        x = self.flow(x)\n",
    "        y = self.spatial(y)\n",
    "        xy_cat = t.cat((x, y), 1)\n",
    "        output = self.fc3(self.relu(self.fc2(xy_cat)))\n",
    "        output1 = self.fc4(self.relu(x))\n",
    "        output2 = self.fc5(self.relu(y))\n",
    "        return output, output1, output2\n",
    "    \n",
    "    def get_optimizer(self, lr, weight_decay):\n",
    "        \n",
    "        return Adam(self.parameters(), lr = lr, weight_decay = weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet121_Spatial(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121_Spatial, self).__init__()\n",
    "        self.model = densenet121(pretrained = True)\n",
    "        self.model.classifier = nn.Sequential()\n",
    "        for params in self.parameters():\n",
    "            params.requires_grad = False\n",
    "        self.fc1 = nn.Linear(1024, 256)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        feature = self.fc1(x)\n",
    "        return feature\n",
    "    \n",
    "    def get_optimizer(self, lr, weight_decay):\n",
    "        \n",
    "        return Adam(self.parameters(), lr = lr, weight_decay = weight_decay)\n",
    "    \n",
    "class DenseNet121_Flow(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121_Flow, self).__init__()\n",
    "        self.model = densenet121(pretrained = True)\n",
    "        self.model.classifier = nn.Sequential()\n",
    "        for params in self.parameters():\n",
    "            params.requires_grad = False\n",
    "        self.fc1 = nn.Linear(1024, 256)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        feature = self.fc1(x)\n",
    "        return feature\n",
    "    \n",
    "    def get_optimizer(self, lr, weight_decay):\n",
    "        \n",
    "        return Adam(self.parameters(), lr = lr, weight_decay = weight_decay)\n",
    "                    \n",
    "class DenseNet121_Flow_Spatial(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121_Flow_Spatial, self).__init__()\n",
    "        self.flow = DenseNet121_Flow()\n",
    "        self.spatial = DenseNet121_Spatial()\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 2)\n",
    "        self.fc4 = nn.Linear(256, 2)\n",
    "        self.fc5 = nn.Linear(256, 2)\n",
    "            \n",
    "    def forward(self, x, y):\n",
    "        x = self.flow(x)\n",
    "        y = self.spatial(y)\n",
    "        xy_cat = t.cat((x, y), 1)\n",
    "        output = self.fc3(self.relu(self.fc2(xy_cat)))\n",
    "        output1 = self.fc4(self.relu(x))\n",
    "        output2 = self.fc5(self.relu(y))\n",
    "        return output, output1, output2\n",
    "    \n",
    "    def get_optimizer(self, lr, weight_decay):\n",
    "        \n",
    "        return Adam(self.parameters(), lr = lr, weight_decay = weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VIT_Spatial(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VIT_Spatial, self).__init__()\n",
    "        self.model = vit_b_16(weights=ViT_B_16_Weights)\n",
    "        self.model.heads = nn.Sequential()\n",
    "        for params in self.parameters():\n",
    "            params.requires_grad = False\n",
    "        self.fc1 = nn.Linear(768, 256)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        feature = self.fc1(x)\n",
    "        return feature\n",
    "    \n",
    "    def get_optimizer(self, lr, weight_decay):\n",
    "        \n",
    "        return Adam(self.parameters(), lr = lr, weight_decay = weight_decay)\n",
    "    \n",
    "class VIT_Flow(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VIT_Flow, self).__init__()\n",
    "        self.model = vit_b_16(weights=ViT_B_16_Weights)\n",
    "        self.model.heads = nn.Sequential()\n",
    "        for params in self.parameters():\n",
    "            params.requires_grad = False\n",
    "        self.fc1 = nn.Linear(768, 256)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        feature = self.fc1(x)\n",
    "        return feature\n",
    "    \n",
    "    def get_optimizer(self, lr, weight_decay):\n",
    "        \n",
    "        return Adam(self.parameters(), lr = lr, weight_decay = weight_decay)\n",
    "                    \n",
    "class ViTB16_Flow_Spatial(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ViTB16_Flow_Spatial, self).__init__()\n",
    "        self.flow = VIT_Flow()\n",
    "        self.spatial = VIT_Spatial()\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 2)\n",
    "        self.fc4 = nn.Linear(256, 2)\n",
    "        self.fc5 = nn.Linear(256, 2)\n",
    "            \n",
    "    def forward(self, x, y):\n",
    "        x = self.flow(x)\n",
    "        y = self.spatial(y)\n",
    "        xy_cat = t.cat((x, y), 1)\n",
    "        output = self.fc3(self.relu(self.fc2(xy_cat)))\n",
    "        output1 = self.fc4(self.relu(x))\n",
    "        output2 = self.fc5(self.relu(y))\n",
    "        return output, output1, output2\n",
    "    \n",
    "    def get_optimizer(self, lr, weight_decay):\n",
    "        \n",
    "        return Adam(self.parameters(), lr = lr, weight_decay = weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinB_Flow(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SwinB_Flow, self).__init__()\n",
    "        self.model = swin_b(weights = Swin_B_Weights.IMAGENET1K_V1)\n",
    "        self.model.head = nn.Sequential()\n",
    "        for params in self.parameters():\n",
    "            params.requires_grad = False\n",
    "        self.fc1 = nn.Linear(1024, 256)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        feature = self.fc1(x)\n",
    "        return feature\n",
    "\n",
    "    def get_optimizer(self, lr, weight_decay):\n",
    "        \n",
    "        return Adam(self.parameters(), lr = lr, weight_decay = weight_decay)    \n",
    "\n",
    "class SwinB_Spatial(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SwinB_Spatial, self).__init__()\n",
    "        self.model = swin_b(weights = Swin_B_Weights.IMAGENET1K_V1)\n",
    "        self.model.head = nn.Sequential()\n",
    "        for params in self.parameters():\n",
    "            params.requires_grad = False\n",
    "        self.fc1 = nn.Linear(1024, 256)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        feature = self.fc1(x)\n",
    "        return feature\n",
    "\n",
    "    def get_optimizer(self, lr, weight_decay):\n",
    "        \n",
    "        return Adam(self.parameters(), lr = lr, weight_decay = weight_decay) \n",
    "    \n",
    "class SwinB_Flow_Spatial(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SwinB_Flow_Spatial, self).__init__()\n",
    "        self.flow = SwinB_Flow()\n",
    "        self.spatial = SwinB_Spatial()\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 2)\n",
    "        self.fc4 = nn.Linear(256, 2)\n",
    "        self.fc5 = nn.Linear(256, 2)\n",
    "            \n",
    "    def forward(self, x, y):\n",
    "        x = self.flow(x)\n",
    "        y = self.spatial(y)\n",
    "        xy_cat = t.cat((x, y), 1)\n",
    "        output = self.fc3(self.relu(self.fc2(xy_cat)))\n",
    "        output1 = self.fc4(self.relu(x))\n",
    "        output2 = self.fc5(self.relu(y))\n",
    "        return output, output1, output2\n",
    "    \n",
    "    def get_optimizer(self, lr, weight_decay):\n",
    "        \n",
    "        return Adam(self.parameters(), lr = lr, weight_decay = weight_decay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset(csv_path, root):\n",
    "    csv_path = os.path.join(root, csv_path)\n",
    "    print (csv_path)\n",
    "    train_img = []\n",
    "    valid_img = []\n",
    "    test_img = []\n",
    "    if csv_path.split('.')[0].split('/')[-1].split('_')[0] == 'train':\n",
    "        x = train_img\n",
    "    elif csv_path.split('.')[0].split('/')[-1].split('_')[0]  == 'valid':\n",
    "        x = valid_img\n",
    "    else:\n",
    "        x = test_img\n",
    "    with open(csv_path,'r') as file_object:\n",
    "        reader = csv.reader(file_object)\n",
    "        for i, data in enumerate(reader):\n",
    "            x.append(data[0])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCVD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SCVD_Dataset(data.Dataset):\n",
    "    def __init__(self, img1, img2, train, test):\n",
    "        super(SCVD_Dataset, self).__init__()\n",
    "        \n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.img1 = img1\n",
    "        self.img2 = img2\n",
    "    \n",
    "        normalize = T.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                                std = [0.229, 0.224, 0.225])\n",
    "\n",
    "        if self.train: \n",
    "            self.transforms = T.Compose([\n",
    "                T.RandomHorizontalFlip(p = 0.5),  \n",
    "                T.RandomVerticalFlip(p = 0.5), \n",
    "                T.ToTensor(),\n",
    "                normalize\n",
    "            ])\n",
    "        else:\n",
    "            self.transforms = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                normalize\n",
    "            ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        img_path1 = self.img1[index]\n",
    "        root = img_path1\n",
    "        if img_path1.split('/')[3] == 'transparency_print':\n",
    "            label =  0\n",
    "        else:\n",
    "            label =  1 if img_path1.split('.')[-2].split('/')[-1].split('_')[1] == 'NONE' else 0    \n",
    "        \n",
    "        pic1 = Image.open(img_path1)\n",
    "        data1 = self.transforms(pic1)\n",
    "        \n",
    "        img_path2 = self.img2[index]    \n",
    "        pic2 = Image.open(img_path2)\n",
    "        data2 = self.transforms(pic2)\n",
    "        \n",
    "        return data1, data2, label, root\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CMFL(nn.Module):\n",
    "\t\"\"\"\n",
    "\tCross Modal Focal Loss\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, alpha = 1, gamma = 2, binary = False, multiplier = 2, sg = False):\n",
    "\t\tsuper(CMFL, self).__init__()\n",
    "\t\tself.alpha = alpha\n",
    "\t\tself.gamma = gamma\n",
    "\t\tself.binary = binary\n",
    "\t\tself.multiplier =multiplier\n",
    "\t\tself.sg = sg\n",
    "\n",
    "\tdef forward(self, inputs_a, inputs_b, targets):\n",
    "        \n",
    "\t\tbce_loss_a = criterion(inputs_a, targets)\n",
    "\t\tbce_loss_b = criterion(inputs_b, targets)\n",
    "\n",
    "\t\tpt_a = t.exp(-bce_loss_a)\n",
    "\t\tpt_b = t.exp(-bce_loss_b)\n",
    "\n",
    "\t\teps = 0.000000001\n",
    "\n",
    "\t\tif self.sg:\n",
    "\t\t\td_pt_a = pt_a.detach()\n",
    "\t\t\td_pt_b = pt_b.detach()\n",
    "\t\t\twt_a = ((d_pt_b + eps)*(self.multiplier * pt_a * d_pt_b))/(pt_a + d_pt_b + eps)\n",
    "\t\t\twt_b = ((d_pt_a + eps)*(self.multiplier * d_pt_a * pt_b))/(d_pt_a + pt_b + eps)\n",
    "\t\telse:\n",
    "\t\t\twt_a = ((pt_b + eps)*(self.multiplier * pt_a * pt_b))/(pt_a + pt_b + eps)\n",
    "\t\t\twt_b = ((pt_a + eps)*(self.multiplier * pt_a * pt_b))/(pt_a + pt_b + eps)\n",
    "\n",
    "\t\tif self.binary:\n",
    "\t\t\twt_a = wt_a * (1 - targets)\n",
    "\t\t\twt_b = wt_b * (1 - targets)\n",
    "\n",
    "\t\tf_loss_a = self.alpha * (1 - wt_a)**self.gamma * bce_loss_a\n",
    "\t\tf_loss_b = self.alpha * (1 - wt_b)**self.gamma * bce_loss_b\n",
    "\n",
    "\t\tloss= 0.5 * t.mean(f_loss_a) + 0.5 * t.mean(f_loss_b) \n",
    "\t\t\n",
    "\t\treturn loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CSV For AUC EER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_csv(results, file_name):\n",
    "\n",
    "    with open(file_name, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['id', 'score','root'])\n",
    "        writer.writerows(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Visualizer(object):\n",
    "    def __init__(self, env='default', **kwargs):\n",
    "        self.vis = visdom.Visdom(env=env,use_incoming_socket=False, **kwargs)\n",
    "\n",
    "        self.index = {}\n",
    "        self.log_text = ''\n",
    "\n",
    "    def reinit(self, env='default', **kwargs):\n",
    "\n",
    "        self.vis = visdom.Visdom(env=env, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def plot_many(self, d):\n",
    "\n",
    "        for k, v in d.items():\n",
    "            self.plot(k, v)\n",
    "\n",
    "    def img_many(self, d):\n",
    "        for k, v in d.items():\n",
    "            self.img(k, v)\n",
    "\n",
    "    def plot(self, name, y, **kwargs):\n",
    "\n",
    "        x = self.index.get(name, 0)\n",
    "        self.vis.line(Y=np.array([y]), X=np.array([x]),\n",
    "                      win=name,\n",
    "                      opts=dict(title=name),\n",
    "                      update=None if x == 0 else 'append',\n",
    "                      **kwargs\n",
    "                      )\n",
    "        self.index[name] = x + 1\n",
    "\n",
    "    def img(self, name, img_, **kwargs):\n",
    "\n",
    "        self.vis.images(img_.cpu().numpy(),\n",
    "                        win=name,\n",
    "                        opts=dict(title=name),\n",
    "                        **kwargs\n",
    "                        )\n",
    "\n",
    "    def log(self, info, win='log_text'):\n",
    "        self.log_text += ('[{time}] {info} <br>'.format(\n",
    "            time=time.strftime('%m%d_%H%M%S'),\n",
    "            info=info))\n",
    "        self.vis.text(self.log_text, win)\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self.vis, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train And Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(**kwargs):\n",
    "    \n",
    "    \n",
    "    img_flow_train = get_dataset(opt.train_flow_data, root = './')\n",
    "    img_flow_valid = get_dataset(opt.valid_flow_data, root = './')\n",
    "    \n",
    "    img_spatial_train = get_dataset(opt.train_spatial_data, root = './')\n",
    "    img_spatial_valid = get_dataset(opt.valid_spatial_data, root = './')\n",
    "    \n",
    "    c = list(zip(img_flow_train, img_spatial_train))\n",
    "    random.shuffle(c)\n",
    "    img_flow_train, img_spatial_train = zip(*c)\n",
    "    \n",
    "    opt._parse(kwargs)\n",
    "    vis = Visualizer(opt.env, port = opt.vis_port)\n",
    "    model = ResNet50_Flow_Spatial()\n",
    "    \n",
    "    model.to(opt.device)\n",
    "\n",
    "    print('The number of training data: {}'.format(len(img_flow_train)))\n",
    "    print('The number of Validing data: {}'.format(len(img_flow_valid)))\n",
    "    \n",
    "    train_data = SCVD_Dataset(img_flow_train, img_spatial_train, train = False, test = False)\n",
    "    train_loader = DataLoader(train_data, batch_size = opt.batch_size_0, shuffle = False, num_workers = opt.num_workers)\n",
    "    \n",
    "    val_data = SCVD_Dataset(img_flow_valid, img_spatial_valid, train = False,  test = True)\n",
    "    val_loader = DataLoader(val_data, batch_size = opt.batch_size_1, shuffle = False, num_workers = opt.num_workers)\n",
    "\n",
    "    criterion1 = nn.CrossEntropyLoss(weight = opt.loss_weight)\n",
    "    criterion2 = CMFL(alpha = 1, gamma = 3, binary= False, multiplier = 2)\n",
    "    \n",
    "    lr = opt.lr\n",
    "   \n",
    "    optimizer = model.get_optimizer(lr, opt.weight_decay)\n",
    "   \n",
    "    loss_meter = meter.AverageValueMeter()\n",
    "    confusion_matrix = meter.ConfusionMeter(2)\n",
    "    previous_loss = 1e10\n",
    "    best_acc = 0\n",
    "\n",
    "    for epoch in range(opt.max_epoch):\n",
    "\n",
    "        loss_meter.reset()\n",
    "        confusion_matrix.reset()\n",
    "        for ii, (data1, data2, label, root) in enumerate(tqdm(train_loader)):\n",
    "            \n",
    "            flow = data1.to(opt.device)\n",
    "            spatial = data2.to(opt.device)\n",
    "            \n",
    "            target = label.to(opt.device)\n",
    "            score, score1, score2 = model(flow, spatial)\n",
    "        \n",
    "            loss1 = criterion1(score, target)\n",
    "            loss2 = criterion2(score1, score2, target)\n",
    "            loss = 0.5 * loss1 + 0.5 * loss2\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_meter.add(loss.item())\n",
    "            confusion_matrix.add(score.detach(), target.detach())  \n",
    "                \n",
    "        cm_accuracy = confusion_matrix.value()\n",
    "        train_accuracy = (cm_accuracy[0][0] + cm_accuracy[1][1]) / (cm_accuracy.sum())\n",
    "        print(\"epoch: {epoch},  training accuracy: {accuracy}\".format(epoch = epoch, accuracy = train_accuracy))\n",
    "\n",
    "        print(\"epoch: {epoch},  loss: {loss}\".format(epoch = epoch,  loss = loss_meter.value()[0]))\n",
    "\n",
    "        cm, acc = val(model, val_loader)\n",
    "        print(\"-epoch: {epoch},  Valid accuracy: {acc}\".format(epoch = epoch,acc = acc))\n",
    "\n",
    "        model_name = opt.save_model + 'ResNet50-Flow-Spatial-{epoch}-{acc}.pth'.format(epoch = epoch, acc = acc)\n",
    "        t.save(model.state_dict(), opt.save_model + 'ResNet50-Flow-Spatial-{epoch}-{acc}.pth'.format(epoch = epoch, acc = acc))\n",
    "        if acc >= best_acc:\n",
    "            best_acc = acc\n",
    "            best_model_name = model_name\n",
    "            \n",
    "        # vis.plot('val_acc', acc)\n",
    "        if loss_meter.value()[0] > previous_loss:          \n",
    "            lr = lr * opt.lr_decay\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "        previous_loss = loss_meter.value()[0]\n",
    "\n",
    "    print(best_model_name)      \n",
    "\n",
    "@t.no_grad()\n",
    "def val(model, dataloader):\n",
    "    model.eval()\n",
    "    confusion_matrix = meter.ConfusionMeter(2)\n",
    "    for ii, (val_input, val_input1, label, root) in enumerate(tqdm(dataloader)):\n",
    "        val_in = val_input.to(opt.device)\n",
    "        val_in1 = val_input1.to(opt.device)\n",
    "        score, score1, score2 = model(val_in, val_in1)\n",
    "        confusion_matrix.add(score.detach(), label.type(t.LongTensor))\n",
    "        \n",
    "    model.train()\n",
    "    cm_value = confusion_matrix.value()\n",
    "    accuracy = (cm_value[0][0] + cm_value[1][1]) / (cm_value.sum())\n",
    "\n",
    "    return confusion_matrix, accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@t.no_grad()\n",
    "def test(**kwargs):\n",
    "    opt._parse(kwargs)\n",
    "    \n",
    "    model = DenseNet121_Flow_Spatial()\n",
    "    \n",
    "    model.load_state_dict(t.load(opt.load_model_path, map_location='cpu'))\n",
    "    \n",
    "    \n",
    "    img_flow_test = get_dataset(opt.test_flow_data, root = './')\n",
    "    img_spatial_test = get_dataset(opt.test_spatial_data, root = './')\n",
    "    \n",
    "    \n",
    "    print('The number of Testing data: {}'.format(len(img_flow_test)))\n",
    "    test_data = SCVD_Dataset(img_flow_test, img_spatial_test, train = False, test = True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size = opt.batch_size_1, shuffle = False, num_workers = opt.num_workers)\n",
    "\n",
    "    model.to(opt.device)\n",
    "    results = []\n",
    "    confusion_matrix = meter.ConfusionMeter(2)\n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    for data1, data2, label, root in tqdm(test_dataloader):\n",
    "        input1 = data1.to(opt.device)\n",
    "        input2 = data2.to(opt.device)\n",
    "        score, score1, score2 = model(input1, input2)\n",
    "\n",
    "        output = F.softmax(score, dim=1)[:, 1].detach().tolist()\n",
    "        \n",
    "        confusion_matrix.add(score.detach(), label.type(t.LongTensor))\n",
    "        \n",
    "\n",
    "\n",
    "        batch_results = [(label_.item(), output_ ,root_ ) for label_, output_ , root_ in zip(label, output , root)]\n",
    "        results += batch_results\n",
    "\n",
    "       \n",
    "    write_csv(results, opt.result_file)\n",
    "    cm_value = confusion_matrix.value()\n",
    "    accuracy = (cm_value[0][0] + cm_value[1][1]) / (cm_value.sum())\n",
    "    print(\"Test accuracy: {}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compute AUC EER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "import os\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import shutil\n",
    "\n",
    "def EER(FPR,TPR,threshold):\n",
    "    \"\"\" Returns equal error rate (EER) and the corresponding threshold. \"\"\"\n",
    "    FNR = 1-TPR\n",
    "    abs_diffs = np.abs(FPR - FNR)\n",
    "    min_index = np.argmin(abs_diffs)\n",
    "    eer = np.mean((FPR[min_index], FNR[min_index]))\n",
    "    return eer, threshold[min_index]\n",
    "\n",
    "\n",
    "def ComputeMetric(y_true, y_score, pos_label=1, isPlot=False, model_name='estimator', fig_path='.'):\n",
    "\n",
    "    AUC = metrics.roc_auc_score(y_true, y_score)\n",
    "    \n",
    "    FPR, TPR, threshold = metrics.roc_curve(y_true, y_score, pos_label=pos_label)\n",
    "    eer, best_threshold = EER(FPR, TPR, threshold)\n",
    "    \n",
    "    # if isPlot:\n",
    "    #     display = metrics.RocCurveDisplay(fpr=FPR, tpr=TPR, roc_auc=AUC,\n",
    "    #                                       estimator_name=model_name)\n",
    "    #     display.plot()\n",
    "    #     if not fig_path is None:\n",
    "    #         plt.savefig(os.path.join(fig_path, model_name+'.png'))\n",
    "    #     plt.show()\n",
    "\n",
    "    return AUC, eer, best_threshold\n",
    "\n",
    "\n",
    "def evaluation(csv_path, root='./', image = True):\n",
    "    csv_path = os.path.join(root, csv_path)\n",
    "    print (csv_path)\n",
    "    img_dict = defaultdict(dict)\n",
    "    model_name = csv_path.split('/')[-1].split('.')[0]\n",
    "    with open(csv_path,'r') as file_object:\n",
    "        reader = csv.reader(file_object)\n",
    "        for i, data in enumerate(reader):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            label = int(data[0])\n",
    "            score = float(data[1])\n",
    "\n",
    "            if image == True:   \n",
    "                img_name = '_'.join(data[2].split('_')[:-1]) \n",
    "            else:\n",
    "                img_name = data[2]                                   \n",
    "\n",
    "            if not img_name in img_dict.keys():\n",
    "                img_dict[img_name] = {'label': label, 'num': 1, 'score':[score]}\n",
    "            else:\n",
    "                img_dict[img_name]['num'] += 1\n",
    "                img_dict[img_name]['score'] += [score]\n",
    "\n",
    "        print (len(img_dict))\n",
    "\n",
    "        y_ture = np.array([])\n",
    "        y_score = np.array([])\n",
    "\n",
    "        false=[]\n",
    "        for k, v in img_dict.items():\n",
    "\n",
    "            score_averagy = sum(v['score']) / v['num']\n",
    "            y_ture = np.append(y_ture, v['label']) \n",
    "            y_score = np.append(y_score, score_averagy)\n",
    "\n",
    "        auc, eer, best_thresh = ComputeMetric(y_ture, y_score, isPlot=True,\\\n",
    "                                            model_name=model_name)\n",
    "        print ('len : ', y_ture.shape)\n",
    "        print ('model_name: ', model_name, ' auc: ', auc, ' eer: ', eer, \\\n",
    "            ' best_thresh: ', best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = opt.result_file\n",
    "evaluation(csv_path, root='./', image = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chen",
   "language": "python",
   "name": "chen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
